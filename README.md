# Projet final : Traitement en quasi-temps r√©el de donn√©es a√©riennes

## Technologies utilis√©es
- Apache NiFi ‚Üí pour l‚Äôingestion de donn√©es
- Apache Kafka ‚Üí pour le streaming distribu√©
- Apache Spark (Batch ou Streaming) ‚Üí pour le traitement distribu√©
- Postgres ‚Üí pour le stockage distribu√©
- Grafana ‚Üí pour la visualisation finale
- Docker & Docker Compose ‚Üí pour la mise en place de l‚Äôenvironnement 

## Contexte et Objectif du projet
Ces outils ont √©t√© utilis√©s pour le d√©veloppement du projet sur les donn√©es a√©riennes, visant √† analyser en quasi-temps r√©el les donn√©es du trafic a√©rien. Ce projet nous permet de mettre en place une cha√Æne compl√®te en passant par l'extraction, le traitement, la transformation, et la visualisation de donn√©es a√©riennnes, tout en mobilisant plusieurs outils Big Data dans un 
environnement Dockeris√©. 
L‚Äôobjectif est de construire un pipeline ETL (Extract ‚Äì Transform ‚Äì Load) distribu√©, capable de traiter en quasi temps r√©el un flux de donn√©es issues d‚ÄôAPI publiques, et pour notre cas ce sont sur les flux de donn√©es a√©riens.

## Objectifs p√©dagogiques 
- Mettre en place une cha√Æne ETL distribu√©e en environnement conteneuris√© (ici Docker)
- G√©rer un flux de donn√©es en quasi temps r√©el via Kafka et Spark
- Exp√©rimenter le stockage et la consultation de donn√©es dans un syst√®me distribu√© 
- R√©aliser un tableau de bord BI interactif avec des donn√©es a√©riennes r√©elles 
- Projet √† mener en 1 semaine par groupe de 2 √©tudiants 

## Source de donn√©es / API utilis√©e
Nous avions un choix d'API √† faire parmi plusieurs API publique et a√©rienne et notre choix s'est port√© sur OpenAIP qui contient des donn√©es a√©ronautiques mondiales actuelles et pr√©cises.

## Architecture du projet 
INSERER NOTRE ARCHITECTURE !!!

## √âtapes du projet

1. **Ingestion des donn√©es du trafic a√©rien** :
   - R√©cup√©ration des donn√©es sur le flux du trafic a√©rien en temps r√©el via l'API "OpenAIP" disponible en ligne puis en envoi des donn√©es dans Kafta, en passant par Apache NIFI.
  
2. **Centralisation des messages**:
   - Apr√®s l'envoi des donn√©es dans Kafka, centralisation des messages produits par NIFI pour les rendre disponible pour Spark.

3. **Traitement des donn√©es**:
   - Traitement des donn√©es dans Spark avec nettoyage et agr√©gation pour avoir des donn√©es propres qui seront exploitables.
   
4. **Stockage Distribu√©**:
   - Sauvegarde des donn√©es dans une base consultable (PostGres).
     
5. **Visualisation et Analyse**:
   - Grafana est utilis√© pour cr√©er des tableaux de bord interactifs, permettant de suivre l'√©tat du trafic a√©rien.

## D√©roulement technique du projet
### Ingestion avec NIFI & Envoi dans Kafka
R√©cup√©ration des donn√©es et Ingestion des donn√©es dans NIFI et envoi dans Kafka (voir capture pour le sch√©ma dans NIFI).
<img width="1552" height="379" alt="Capture d'√©cran 2025-10-29 134902" src="https://github.com/user-attachments/assets/d33f4567-ab01-4ba8-87c0-2a868e881d91" />

### Centralisation et envoi dans Spark
mettre une capture
### description du pipeline
.....

## D√©ploiement 
....

## Visualisation des donn√©es avec Grafana
....

## Difficult√©s rencontr√©es
.....

## üìú Conclusion <a name="conclusion"></a>
....

## Contributeurs
- Solenn COULON (@solennCoulon17): Data engineer - **solenn.coulon@supdevinci-edu.fr**
- Coline TREILLE (@Coline-T) : Data analyst - **coline.treille@supdevinci-edu.fr**

